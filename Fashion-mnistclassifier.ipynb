{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 20:40:39.001530: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "learning_rate = 1e-4\n",
    "training_iterations = 2500\n",
    "\n",
    "dropout = 0.5\n",
    "batch_size = 50\n",
    "validation_size = 2000\n",
    "\n",
    "Image_to_display = 10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data60000,785\n",
      "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0      2       0       0       0       0       0       0       0       0   \n",
      "1      9       0       0       0       0       0       0       0       0   \n",
      "2      6       0       0       0       0       0       0       0       5   \n",
      "3      0       0       0       0       1       2       0       0       0   \n",
      "4      3       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0        30        43         0   \n",
      "3       0  ...         3         0         0         0         0         1   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel781  pixel782  pixel783  pixel784  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/s5613008/Final_project/data/fashion-mnist_train.csv')\n",
    "print('data{0[0]},{0[1]}'.format(data.shape))\n",
    "print (data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(float)\n",
    "\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "image_width = 28\n",
    "image_height = 28\n",
    "\n",
    "#print('images{0[0]},{0[1]}'.format(images.shape))\n",
    "\n",
    "labels = data['label'].values\n",
    "labels_one_hot = to_categorical(labels)\n",
    "labels_count = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images, train_labels, validation_labels = train_test_split(images, labels_one_hot, test_size=validation_size, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((-1, 28, 28, 1))\n",
    "validation_images = validation_images.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train：(58000, 28)\n",
      "shape of validation：(2000, 28)\n"
     ]
    }
   ],
   "source": [
    "print('shape of train：({}, {})'.format(train_images.shape[0], train_images.shape[1]))\n",
    "print('shape of validation：({}, {})'.format(validation_images.shape[0], validation_images.shape[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display(img):\n",
    "    one_size = img.reshape(image_width, image_height)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_size, cmap=cm.binary)\n",
    "\n",
    "display(images[Image_to_display])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Conv2D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 20:41:28.217233: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "class MyConv2D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super(MyConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_channels = input_shape[-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(\"kernel\", shape=(self.kernel_size, self.kernel_size, input_channels, self.filters))\n",
    "        self.bias = self.add_weight(\"bias\", shape=(self.filters,))\n",
    "        super(MyConv2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        conv_output = tf.nn.conv2d(inputs, self.kernel, strides=[1, 1, 1, 1], padding='SAME') + self.bias\n",
    "        return tf.nn.relu(conv_output)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "model.add(MyConv2D(filters=32, kernel_size=5))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(MyConv2D(filters=64, kernel_size=5))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(units=labels_count, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-4\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath='/home/s5613008/Final_project/model_checkpoint',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir='/home/s5613008/Final_project/logs', histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 20:42:11.097867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:42:11.192074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:42:39.179361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:42:39.261089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:43:06.980958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:43:07.062550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:43:35.318503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:43:35.399480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:44:03.923979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:44:04.007151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:44:32.439521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:44:32.521825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:45:00.981522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:45:01.064318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:45:29.378926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:45:29.460194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n",
      "2024-01-25 20:46:24.898645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-25 20:46:24.982658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/s5613008/Final_project/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6238824129104614, 0.4034978449344635, 0.35418254137039185, 0.32372191548347473, 0.30288711190223694, 0.2863200902938843, 0.2755577564239502, 0.26645010709762573, 0.2595371901988983, 0.2523469030857086]\n",
      "[0.7738792896270752, 0.8537068963050842, 0.8713620901107788, 0.8819137811660767, 0.8909655213356018, 0.8961896300315857, 0.900672435760498, 0.9042068719863892, 0.9057758450508118, 0.9093965291976929]\n",
      "[0.41210004687309265, 0.3443351089954376, 0.30967825651168823, 0.2986469864845276, 0.28022998571395874, 0.27056246995925903, 0.26468271017074585, 0.25632792711257935, 0.2551692724227905, 0.25125598907470703]\n",
      "[0.8519999980926514, 0.8799999952316284, 0.8889999985694885, 0.8955000042915344, 0.9010000228881836, 0.906000018119812, 0.9075000286102295, 0.9085000157356262, 0.9085000157356262, 0.9104999899864197]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "history = model.fit(\n",
    "    train_images, train_labels, \n",
    "    epochs=num_epochs, batch_size=batch_size, \n",
    "    validation_data=(validation_images, validation_labels),\n",
    "    callbacks=[early_stopping, model_checkpoint, tensorboard_callback],\n",
    "    verbose=0 \n",
    ")\n",
    "print(history.history['loss']) \n",
    "print(history.history['accuracy']) \n",
    "print(history.history['val_loss'])  \n",
    "print(history.history['val_accuracy']) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "random_indices = np.random.choice(validation_images.shape[0], size=5, replace=False)\n",
    "sample_images = validation_images[random_indices]\n",
    "\n",
    "predictions = model.predict(sample_images)\n",
    "\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(1, len(sample_images), i+1)\n",
    "    plt.imshow(sample_images[i].reshape(image_width, image_height), cmap=cm.binary)\n",
    "    plt.title(f\"Predicted: {np.argmax(predictions[i])}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ase-lsystems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
